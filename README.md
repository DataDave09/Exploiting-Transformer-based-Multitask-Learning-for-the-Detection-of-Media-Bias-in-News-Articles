# Exploiting-Transformer-based-Multitask-Learning-for-the-Detection-of-Media-Bias-in-News-Articles
This repository contains scripts,data files, and results corresponding to my master thesis "Exploiting Transformer-based Multitask Learning for the Detection of Media Bias in News Articles" 

All data files required to run the script are provided at https://drive.google.com/drive/folders/1JOf3PELNI4n136fmvqodjjqi4rRp0hjy?usp=sharing
All Multitask models can be found at https://drive.google.com/drive/folders/1s5netzimpnld-TMo3aZzyggBViERF3yT?usp=sharing

# Description of scripts:

# Description of data files (Note: Every scripts indicates required data at the beginning)
- "labeled_dataset_experts.xlsx": 1700 sentences extracted from news articles and labeled by 8 expert annotators. The labels ("Biased" or "Non-biased" are provided on sentence level)
- "labeled_dataset_cs.xlsx": the same 1700 sentences extracted from news articles but labeled by crowdsourcers (~10 cs per sentence). The labels ("Biased" or "Non-biased" are provided on sentence level)
- "wikipedia_dataset.xlsx", "subjectivity_dataset.xlsx", "STS-B.xlsx", "SNLI.xlsx", "Reddit_dataset.csv" : Data sets used for Multitask Learning approach --> see section 2.6.2
- "Wiki_train.pt", "Wiki_test.pt", "IMDB_train.pt", "IMDB_test.pt", "SNLI_train.pt", "SNLI_test.pt" : pre-processed TensorDatasets that can be directly loaded when applying MTL to save time and computing resources
- "classifier.weights.pt", "classifier.bias.pt": parameters for classification layer that is stacked on top of DistilBERT for fine-tuning on the bias dataset. In all experiments, I initialized the model with identical parameters to achieve maximum possible comparability.
- "labels_3annotators.xlsx","labels_5annotators.xlsx","labels_7annotators.xlsx","labels_9annotators.xlsx": The 1700 sentences labeled by different numbers of crowdsourcers (see section 4.3.1 "Crowdsource-based Quality Analysis")
