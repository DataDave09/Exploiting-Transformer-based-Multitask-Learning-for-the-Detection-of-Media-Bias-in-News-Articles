# Exploiting-Transformer-based-Multitask-Learning-for-the-Detection-of-Media-Bias-in-News-Articles
This repository contains scripts,data files, and results corresponding to my master thesis "Exploiting Transformer-based Multitask Learning for the Detection of Media Bias in News Articles" 

- All data files required to run the script are provided at https://drive.google.com/drive/folders/1JOf3PELNI4n136fmvqodjjqi4rRp0hjy?usp=sharing
- All Multitask models can be found at https://drive.google.com/drive/folders/1s5netzimpnld-TMo3aZzyggBViERF3yT?usp=sharing
- Results for all experiments can be found at /results 

# Description of scripts:(Note: Every script indicates required data files at the beginning)
- "new_sentences_EDA.ipynb": Script calculating and plotting label and topic distribution of 2000 additionally collected sentences (corresponds to section 3.2.2)
- "Quality_analysis.ipynb": Script corresponding to the crowdsource-based quality analyses (corresponds to section 4.3.1)
- "Quantity_analyses_crowdsourcing.ipynb": Script corresponding to the crowdsource-based quantity analyses (corresponds to section 4.3.2)
- "Quantity_analyses_crowdsourcing.ipynb": Script corresponding to the expert-based quantity analyses (corresponds to section 4.3.3)
- "Experts_vs_Crowdourcers.ipynb": Script comparing DistilBERT's performance on the crowdsourced and expert dataset (corresponds to section 4.4)
- "Multitask_Learning.ipynb": Computation of Multi-task Learning models based on DistilBERT (corresponds to section 4.5)
- "Evaluate_MTL.ipynb": Evaluation of MTL models based on the bias dataset. (corresponds to section 4.5)
- "Few_shot_learning.iypnb": Script implementing the few-shot learning approach based on the best-performing MTL model  (corresponds to section 4.6)

# Description of data files 
- "labeled_dataset_experts.xlsx": 1700 sentences extracted from news articles and labeled by 8 expert annotators. The labels ("Biased" or "Non-biased" are provided on sentence level).
- "labeled_dataset_cs.xlsx": the same 1700 sentences extracted from news articles but labeled by crowdsourcers (~10 cs per sentence). The labels ("Biased" or "Non-biased" are provided on sentence level).
- "wikipedia_dataset.xlsx", "subjectivity_dataset.xlsx", "STS-B.xlsx", "SNLI.xlsx", "Reddit_dataset.csv" : Data sets used for Multitask Learning approach (see section 2.6.2)
- "Wiki_train.pt", "Wiki_test.pt", "IMDB_train.pt", "IMDB_test.pt", "SNLI_train.pt", "SNLI_test.pt" : pre-processed TensorDatasets that can be directly loaded when applying MTL to save time and computing resources.
- "classifier.weights.pt", "classifier.bias.pt": parameters for classification layer that is stacked on top of DistilBERT for fine-tuning on the bias dataset. In all experiments, I initialized the model with identical parameters to achieve maximum possible comparability.
- "labels_3annotators.xlsx","labels_5annotators.xlsx","labels_7annotators.xlsx","labels_9annotators.xlsx": The 1700 sentences labeled by different numbers of crowdsourcers (see section 4.3.1 "Crowdsource-based Quality Analysis").
- "new_sentence_collection.xlsx": 2000 additionally collected but unlabeled sentences.
