{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Quantity_analysis_experts.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b258514f766e46a38482b9a873f931f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_680ea81f68cb4ba6b9036f890f402c8d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_383ed76b497f4e4fa66df53fce36c004",
              "IPY_MODEL_495d7377f10a413ba59f582aa139f9bd"
            ]
          }
        },
        "680ea81f68cb4ba6b9036f890f402c8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "383ed76b497f4e4fa66df53fce36c004": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_319120e080914c08a0a1a987f35ba359",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 442,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 442,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_affe5f8d9ac9411bbb13c15d315c793f"
          }
        },
        "495d7377f10a413ba59f582aa139f9bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5269937261c24a62b09f74d9ceea075b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 442/442 [00:10&lt;00:00, 42.8B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e1b624544fab4fdba82da6cf741cb750"
          }
        },
        "319120e080914c08a0a1a987f35ba359": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "affe5f8d9ac9411bbb13c15d315c793f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5269937261c24a62b09f74d9ceea075b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e1b624544fab4fdba82da6cf741cb750": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5f7cfb575eea4e9480e2e728e522c2ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2c08daabce744ed1926ae612c2dd72cb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_190e20964cbc4db893fa850eb601e624",
              "IPY_MODEL_a212b6ad3f5b49e29cd41886976ae6a9"
            ]
          }
        },
        "2c08daabce744ed1926ae612c2dd72cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "190e20964cbc4db893fa850eb601e624": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f506478c5014406e8943ce112ff3bf30",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 267967963,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 267967963,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ad23d027cd254226899effd609bd7685"
          }
        },
        "a212b6ad3f5b49e29cd41886976ae6a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6775282e09684bf1b86973f8136156f0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 268M/268M [00:09&lt;00:00, 27.6MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f84adb4c28de4ebfb2b19211419a2eca"
          }
        },
        "f506478c5014406e8943ce112ff3bf30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ad23d027cd254226899effd609bd7685": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6775282e09684bf1b86973f8136156f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f84adb4c28de4ebfb2b19211419a2eca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpS_REO0vtV6"
      },
      "source": [
        "This script corresponds to section 4.3.3: Expert-based Quantity Analysis\n",
        "\n",
        "Required data to run this script:\n",
        "- labeled_dataset_experts.xlsx\n",
        "- classifier.weight.pt (we initialize all classifiers with the same parameters for the sake of comparability)\n",
        "- classifier.bias.pt (bias for classifier)\n",
        "- quantity_analysis_experts.json (to plot results)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjZWOgnovnc9"
      },
      "source": [
        "!pip install transformers\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import sys\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "from sklearn.model_selection import train_test_split,StratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score,f1_score,precision_score,recall_score,accuracy_score,confusion_matrix\n",
        "import transformers\n",
        "from transformers import AdamW,DistilBertTokenizer,DistilBertModel\n",
        "from torch.utils.data import DataLoader,TensorDataset,SequentialSampler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUbfw4-ivpS5"
      },
      "source": [
        "Connect to drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6VzgU5i7vHob",
        "outputId": "a9fe0110-e54e-4c1e-a357-cd96493eb909"
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtgG6osXvy0T"
      },
      "source": [
        "Define Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivQMG-58v0R6"
      },
      "source": [
        "class DistilBertClass(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DistilBertClass, self).__init__()\n",
        "        self.distilbert = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
        "        self.vocab_transform = torch.nn.Linear(768, 768)\n",
        "        self.dropout = torch.nn.Dropout(0.2)\n",
        "        self.classifier = torch.nn.Linear(768,2)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        output_1 = self.distilbert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        hidden_state = output_1[0]\n",
        "        pooler = hidden_state[:, 0]\n",
        "        pooler = self.vocab_transform(pooler)\n",
        "        pooler = self.dropout(pooler)\n",
        "        output = self.classifier(pooler)\n",
        "\n",
        "        return output"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5papSYrXwAb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190,
          "referenced_widgets": [
            "b258514f766e46a38482b9a873f931f7",
            "680ea81f68cb4ba6b9036f890f402c8d",
            "383ed76b497f4e4fa66df53fce36c004",
            "495d7377f10a413ba59f582aa139f9bd",
            "319120e080914c08a0a1a987f35ba359",
            "affe5f8d9ac9411bbb13c15d315c793f",
            "5269937261c24a62b09f74d9ceea075b",
            "e1b624544fab4fdba82da6cf741cb750",
            "5f7cfb575eea4e9480e2e728e522c2ec",
            "2c08daabce744ed1926ae612c2dd72cb",
            "190e20964cbc4db893fa850eb601e624",
            "a212b6ad3f5b49e29cd41886976ae6a9",
            "f506478c5014406e8943ce112ff3bf30",
            "ad23d027cd254226899effd609bd7685",
            "6775282e09684bf1b86973f8136156f0",
            "f84adb4c28de4ebfb2b19211419a2eca"
          ]
        },
        "outputId": "6bec0cff-4a66-40cd-fade-8ba569cc690c"
      },
      "source": [
        "#define baseline model and save weights\n",
        "model_raw = DistilBertClass()\n",
        "weight_dict = model_raw.state_dict()\n",
        "\n",
        "#load saved classifier weights + classifier bias --> every model is initialized with same classification layers for comparability reasons\n",
        "classifier_weights = torch.load('/content/drive/MyDrive/Masterthesis/Data/classifier.weights.pt')\n",
        "classifier_bias = torch.load('/content/drive/MyDrive/Masterthesis/Data/classifier.bias.pt')\n",
        "\n",
        "#insert predefined weights and bias into weight dict\n",
        "weight_dict['classifier.weight'] = classifier_weights\n",
        "weight_dict['classifier.bias'] = classifier_bias"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b258514f766e46a38482b9a873f931f7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=442.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5f7cfb575eea4e9480e2e728e522c2ec",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=267967963.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBUKr5n8vQZL"
      },
      "source": [
        "Connect to GPU (do not forget to switch on GPU under runtime settings)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2n8HMRqvSLo",
        "outputId": "44d8e5cd-3de3-4573-857f-914ffac46a61"
      },
      "source": [
        "if torch.cuda.is_available():       \n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
        "    print('Device name:', torch.cuda.get_device_name(0))\n",
        "\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No GPU available, using the CPU instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMPL7XrTvZAd"
      },
      "source": [
        "Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzmjSAAiF7TN"
      },
      "source": [
        "df = pd.read_excel(\"./labeled_dataset_experts.xlsx\") #insert path to data\n",
        "\n",
        "#select only cases with agreement\n",
        "df = df[df['label_bias']!= 'No agreement']\n",
        "\n",
        "#encode string variable into binary variable\n",
        "df['Label_bias_0-1'] = df['label_bias'].map({'Biased':1,'Non-biased':0})\n",
        "df = df[['text','Label_bias_0-1']]\n",
        "\n",
        "#split data in train test, so that all sub-datasets of different size are evaluated on same held-out test sample\n",
        "train_data, test_data = train_test_split(df,random_state=2018,test_size=0.2,stratify=df['Label_bias_0-1'])\n",
        "\n",
        "#subsampling of train data containing samples (20%,30%,40%...) of original data\n",
        "df_20 = train_data.groupby('Label_bias_0-1', group_keys=False).apply(lambda x: x.sample(int(np.rint((0.2*len(df))*len(x)/len(df))))).sample(frac=1).reset_index(drop=True)\n",
        "df_30 = train_data.groupby('Label_bias_0-1', group_keys=False).apply(lambda x: x.sample(int(np.rint((0.3*len(df))*len(x)/len(df))))).sample(frac=1).reset_index(drop=True)\n",
        "df_40 = train_data.groupby('Label_bias_0-1', group_keys=False).apply(lambda x: x.sample(int(np.rint((0.4*len(df))*len(x)/len(df))))).sample(frac=1).reset_index(drop=True)\n",
        "df_50 = train_data.groupby('Label_bias_0-1', group_keys=False).apply(lambda x: x.sample(int(np.rint((0.5*len(df))*len(x)/len(df))))).sample(frac=1).reset_index(drop=True)\n",
        "df_60 = train_data.groupby('Label_bias_0-1', group_keys=False).apply(lambda x: x.sample(int(np.rint((0.6*len(df))*len(x)/len(df))))).sample(frac=1).reset_index(drop=True)\n",
        "df_70 = train_data.groupby('Label_bias_0-1', group_keys=False).apply(lambda x: x.sample(int(np.rint((0.7*len(df))*len(x)/len(df))))).sample(frac=1).reset_index(drop=True)\n",
        "df_80 = train_data.groupby('Label_bias_0-1', group_keys=False).apply(lambda x: x.sample(int(np.rint((0.8*len(df))*len(x)/len(df))))).sample(frac=1).reset_index(drop=True)\n",
        "df_90 = train_data.groupby('Label_bias_0-1', group_keys=False).apply(lambda x: x.sample(int(np.rint((0.9*len(df))*len(x)/len(df))))).sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "# create list of all df's\n",
        "dfs = [df_20,df_30,df_40,df_50,df_60,df_70,df_80,df_90,train_data]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdFMb0U2feYy"
      },
      "source": [
        "#prepare test data (it's the same for all subsamples)\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "#divide data into folds\n",
        "test_text = test_data['text']\n",
        "test_labels = test_data['Label_bias_0-1']\n",
        "\n",
        "#encode\n",
        "test_encodings = tokenizer(test_text.tolist(), truncation=True, padding=True)\n",
        "\n",
        "#convert input to tensors \n",
        "test_seq = torch.tensor(test_encodings['input_ids'])\n",
        "test_mask = torch.tensor(test_encodings['attention_mask'])\n",
        "test_y = torch.tensor(test_labels.tolist())\n",
        "\n",
        "# wrap tensors into one dataset\n",
        "test_data = TensorDataset(test_seq, test_mask, test_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DC39z8GFxQtB"
      },
      "source": [
        "Define Cross-Validation,Dataloader,Epochs,Loss, and Seeds"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7LEkeyHxP7B"
      },
      "source": [
        "np.random.seed(0)\n",
        "torch.manual_seed(0)   \n",
        "random.seed(0)    \n",
        "torch.cuda.manual_seed_all(0)\n",
        "random.seed(0)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "kfold = StratifiedKFold(shuffle = True,random_state=2018)\n",
        "cross_entropy = nn.CrossEntropyLoss()\n",
        "\n",
        "epochs = 4\n",
        "batch_size = 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EBHCXpsxc_e"
      },
      "source": [
        "Define functions for training and validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oA6Np8VLxbuF"
      },
      "source": [
        "def train(model):\n",
        "\n",
        "  model.train()\n",
        "  total_loss = 0\n",
        "\n",
        "  for batch in train_dataloader:\n",
        "    optim_dbert.zero_grad()\n",
        "    batch = [r.to(device) for r in batch]\n",
        "    sent_id, mask, labels = batch\n",
        "    outputs = model(sent_id, attention_mask=mask)\n",
        "    loss = cross_entropy(outputs,labels)\n",
        "    total_loss = total_loss+loss.item()\n",
        "    loss.backward()\n",
        "    optim_dbert.step()\n",
        "\n",
        "  avg_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "  return avg_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VvtdBe3xj0h"
      },
      "source": [
        "def validate(model):\n",
        "\n",
        "  model.eval()\n",
        "  total_loss = 0\n",
        "\n",
        "  print(\"\\n   Validating...\")\n",
        "\n",
        "  for batch in test_dataloader:\n",
        "    batch = [r.to(device) for r in batch]\n",
        "    sent_id, mask, labels = batch\n",
        "\n",
        "    with torch.no_grad():\n",
        "      outputs = model(sent_id, attention_mask=mask)\n",
        "      loss = cross_entropy(outputs,labels)\n",
        "      total_loss = total_loss+loss.item()\n",
        "\n",
        "  avg_loss = total_loss / len(test_dataloader) \n",
        "\n",
        "  return avg_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krCHuXqsxn5l"
      },
      "source": [
        "def train_validate_pred(model):\n",
        "  best_valid_loss = float('inf')\n",
        "\n",
        "  # empty lists to store training and validation loss of each epoch\n",
        "  train_losses=[]\n",
        "  valid_losses=[]\n",
        "\n",
        "  #for each epoch\n",
        "  for epoch in range(epochs):\n",
        "      \n",
        "    print('\\n   Epoch {} / {}'.format(epoch+1,epochs))\n",
        "    \n",
        "    #train model\n",
        "    train_loss = train(model)\n",
        "    \n",
        "    #evaluate model\n",
        "    valid_loss = validate(model)\n",
        "    \n",
        "    #save the best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "      best_valid_loss = valid_loss\n",
        "      global model_dbert\n",
        "      torch.save(model_dbert.state_dict(), 'saved_weights.pt')\n",
        "\n",
        "    #if validation loss increases, stop training\n",
        "    elif valid_loss >= best_valid_loss:\n",
        "      print(\"\\n Validation loss not decreased, Model of previous epoch saved\")\n",
        "      break\n",
        "    \n",
        "    print(f'\\n    Training Loss: {train_loss:.3f}')\n",
        "    print(f'    Validation Loss: {valid_loss:.3f}')\n",
        "  \n",
        "  #predict\n",
        "  path = 'saved_weights.pt'\n",
        "  model_dbert.load_state_dict(torch.load(path))\n",
        "  with torch.no_grad():\n",
        "    preds = model_dbert(test_seq.to(device), test_mask.to(device))\n",
        "    preds = preds.detach().cpu().numpy()\n",
        "  preds = np.argmax(preds, axis = 1)\n",
        "  \n",
        "  #save results\n",
        "  loss.append(best_valid_loss)\n",
        "  acc.append(accuracy_score(test_y,preds))\n",
        "  auc.append(roc_auc_score(test_y,preds))\n",
        "  micro_F1.append(f1_score(test_y,preds,average='micro'))\n",
        "  macro_F1_weighted.append(f1_score(test_y,preds,average='weighted'))\n",
        "  binary_F1.append(f1_score(test_y,preds,average='binary'))\n",
        "  precision.append(precision_score(test_y,preds))\n",
        "  recall.append(recall_score(test_y,preds))\n",
        "  conf_matrix = confusion_matrix(test_y, preds)\n",
        "  conf_matrices.append(conf_matrix)\n",
        "\n",
        "  del model_dbert"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8JSM2LfxvRA"
      },
      "source": [
        "Implement cross validation, train/validate the model, and predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eohdRZ05xogi",
        "outputId": "59461a0b-ca1c-411a-c7d8-bbd30a3475f2"
      },
      "source": [
        "#apply cross-validation for all dataframes\n",
        "loss_lst = []\n",
        "#acc_lst = []\n",
        "micro_f1_lst = []\n",
        "macro_f1_lst = []\n",
        "binary_f1_lst = []\n",
        "prec_lst = []\n",
        "recall_lst = []\n",
        "\n",
        "for df in dfs:\n",
        "  print(\"\\n New Dataframe\")\n",
        "\n",
        "  #create new lists to store metrics of every cv repetition\n",
        "  loss = []\n",
        "  acc = []\n",
        "  auc = []\n",
        "  micro_F1 = []\n",
        "  macro_F1_weighted = []\n",
        "  binary_F1 = []\n",
        "  precision = []\n",
        "  recall = []\n",
        "  conf_matrices = []\n",
        "\n",
        "  #apply cross-validation and train/validate/predict for each fold\n",
        "  for fold, (train_index, test_index) in enumerate(kfold.split(df['text'],df['Label_bias_0-1'])):\n",
        "    sys.stdout.write('\\n \\r Fold {} / {}\\n'.format(fold+1,kfold.get_n_splits()))\n",
        "\n",
        "    #divide data into folds\n",
        "    train_text = df['text'].iloc[train_index]\n",
        "    train_labels = df['Label_bias_0-1'].iloc[train_index]\n",
        "\n",
        "    #encode\n",
        "    train_encodings = tokenizer(train_text.tolist(), truncation=True, padding=True)\n",
        "\n",
        "    #convert input to tensors \n",
        "    train_seq = torch.tensor(train_encodings['input_ids'])\n",
        "    train_mask = torch.tensor(train_encodings['attention_mask'])\n",
        "    train_y = torch.tensor(train_labels.tolist())\n",
        "\n",
        "    # wrap tensors into one dataset\n",
        "    train_data = TensorDataset(train_seq, train_mask, train_y)\n",
        "\n",
        "    #define dataloader\n",
        "    train_sampler = SequentialSampler(train_data)\n",
        "    test_sampler = SequentialSampler(test_data)\n",
        "    train_dataloader = DataLoader(train_data,sampler= train_sampler, batch_size=batch_size)\n",
        "    test_dataloader = DataLoader(test_data,sampler = test_sampler, batch_size=batch_size)\n",
        "\n",
        "    #create model and optimizer\n",
        "    model_dbert = DistilBertClass()\n",
        "    model_dbert.load_state_dict(weight_dict)\n",
        "    model_dbert.to(device)\n",
        "    optim_dbert = AdamW(model_dbert.parameters(), lr=1e-5)\n",
        "\n",
        "    #train_validate_predict\n",
        "    train_validate_pred(model=model_dbert)\n",
        "  \n",
        "  #compute final cross validated scores\n",
        "  cv_loss = sum(loss)/len(loss)\n",
        "  cv_micro_f1 = sum(micro_F1)/len(micro_F1)\n",
        "  cv_macro_f1 = sum(macro_F1_weighted)/len(macro_F1_weighted)\n",
        "  cv_binary_f1 = sum(binary_F1)/len(binary_F1)\n",
        "  cv_prec = sum(precision)/len(precision)\n",
        "  cv_recall = sum(recall)/len(recall)\n",
        "\n",
        "  #append scores to list of scores for later plotting\n",
        "  loss_lst.append(cv_loss)\n",
        "  micro_f1_lst.append(cv_micro_f1)\n",
        "  macro_f1_lst.append(cv_macro_f1)\n",
        "  binary_f1_lst.append(cv_binary_f1)\n",
        "  prec_lst.append(cv_prec)\n",
        "  recall_lst.append(cv_recall)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " New Dataframe\n",
            "\n",
            " \r Fold 1 / 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "   Epoch 1 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.704\n",
            "    Validation Loss: 0.685\n",
            "\n",
            "   Epoch 2 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.660\n",
            "    Validation Loss: 0.677\n",
            "\n",
            "   Epoch 3 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.636\n",
            "    Validation Loss: 0.664\n",
            "\n",
            "   Epoch 4 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.596\n",
            "    Validation Loss: 0.647\n",
            "\n",
            " Fold 2 / 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "   Epoch 1 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.696\n",
            "    Validation Loss: 0.684\n",
            "\n",
            "   Epoch 2 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.662\n",
            "    Validation Loss: 0.674\n",
            "\n",
            "   Epoch 3 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.629\n",
            "    Validation Loss: 0.657\n",
            "\n",
            "   Epoch 4 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.583\n",
            "    Validation Loss: 0.638\n",
            "\n",
            " Fold 3 / 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "   Epoch 1 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.705\n",
            "    Validation Loss: 0.684\n",
            "\n",
            "   Epoch 2 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.656\n",
            "    Validation Loss: 0.674\n",
            "\n",
            "   Epoch 3 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.634\n",
            "    Validation Loss: 0.659\n",
            "\n",
            "   Epoch 4 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.606\n",
            "    Validation Loss: 0.644\n",
            "\n",
            " Fold 4 / 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "   Epoch 1 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.695\n",
            "    Validation Loss: 0.683\n",
            "\n",
            "   Epoch 2 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.662\n",
            "    Validation Loss: 0.676\n",
            "\n",
            "   Epoch 3 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.636\n",
            "    Validation Loss: 0.659\n",
            "\n",
            "   Epoch 4 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.593\n",
            "    Validation Loss: 0.634\n",
            "\n",
            " Fold 5 / 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "   Epoch 1 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.699\n",
            "    Validation Loss: 0.683\n",
            "\n",
            "   Epoch 2 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.659\n",
            "    Validation Loss: 0.672\n",
            "\n",
            "   Epoch 3 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.639\n",
            "    Validation Loss: 0.656\n",
            "\n",
            "   Epoch 4 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.597\n",
            "    Validation Loss: 0.638\n",
            "\n",
            " New Dataframe\n",
            "\n",
            " Fold 1 / 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "   Epoch 1 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.696\n",
            "    Validation Loss: 0.680\n",
            "\n",
            "   Epoch 2 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.651\n",
            "    Validation Loss: 0.658\n",
            "\n",
            "   Epoch 3 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.610\n",
            "    Validation Loss: 0.632\n",
            "\n",
            "   Epoch 4 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.557\n",
            "    Validation Loss: 0.606\n",
            "\n",
            " Fold 2 / 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "   Epoch 1 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.693\n",
            "    Validation Loss: 0.680\n",
            "\n",
            "   Epoch 2 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.646\n",
            "    Validation Loss: 0.656\n",
            "\n",
            "   Epoch 3 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.602\n",
            "    Validation Loss: 0.631\n",
            "\n",
            "   Epoch 4 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.541\n",
            "    Validation Loss: 0.603\n",
            "\n",
            " Fold 3 / 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "   Epoch 1 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.694\n",
            "    Validation Loss: 0.681\n",
            "\n",
            "   Epoch 2 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.655\n",
            "    Validation Loss: 0.661\n",
            "\n",
            "   Epoch 3 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.617\n",
            "    Validation Loss: 0.634\n",
            "\n",
            "   Epoch 4 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.558\n",
            "    Validation Loss: 0.609\n",
            "\n",
            " Fold 4 / 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "   Epoch 1 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.688\n",
            "    Validation Loss: 0.680\n",
            "\n",
            "   Epoch 2 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.646\n",
            "    Validation Loss: 0.654\n",
            "\n",
            "   Epoch 3 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.595\n",
            "    Validation Loss: 0.625\n",
            "\n",
            "   Epoch 4 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.525\n",
            "    Validation Loss: 0.600\n",
            "\n",
            " Fold 5 / 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "   Epoch 1 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.691\n",
            "    Validation Loss: 0.680\n",
            "\n",
            "   Epoch 2 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.655\n",
            "    Validation Loss: 0.658\n",
            "\n",
            "   Epoch 3 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.612\n",
            "    Validation Loss: 0.633\n",
            "\n",
            "   Epoch 4 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.553\n",
            "    Validation Loss: 0.605\n",
            "\n",
            " New Dataframe\n",
            "\n",
            " Fold 1 / 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "   Epoch 1 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.690\n",
            "    Validation Loss: 0.677\n",
            "\n",
            "   Epoch 2 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.650\n",
            "    Validation Loss: 0.647\n",
            "\n",
            "   Epoch 3 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.594\n",
            "    Validation Loss: 0.616\n",
            "\n",
            "   Epoch 4 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.514\n",
            "    Validation Loss: 0.578\n",
            "\n",
            " Fold 2 / 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "   Epoch 1 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.685\n",
            "    Validation Loss: 0.675\n",
            "\n",
            "   Epoch 2 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.651\n",
            "    Validation Loss: 0.647\n",
            "\n",
            "   Epoch 3 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.589\n",
            "    Validation Loss: 0.610\n",
            "\n",
            "   Epoch 4 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.508\n",
            "    Validation Loss: 0.575\n",
            "\n",
            " Fold 3 / 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "   Epoch 1 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.687\n",
            "    Validation Loss: 0.675\n",
            "\n",
            "   Epoch 2 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.641\n",
            "    Validation Loss: 0.644\n",
            "\n",
            "   Epoch 3 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.582\n",
            "    Validation Loss: 0.612\n",
            "\n",
            "   Epoch 4 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.513\n",
            "    Validation Loss: 0.579\n",
            "\n",
            " Fold 4 / 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "   Epoch 1 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.689\n",
            "    Validation Loss: 0.675\n",
            "\n",
            "   Epoch 2 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.645\n",
            "    Validation Loss: 0.645\n",
            "\n",
            "   Epoch 3 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.596\n",
            "    Validation Loss: 0.620\n",
            "\n",
            "   Epoch 4 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.531\n",
            "    Validation Loss: 0.598\n",
            "\n",
            " Fold 5 / 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "   Epoch 1 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.689\n",
            "    Validation Loss: 0.675\n",
            "\n",
            "   Epoch 2 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.649\n",
            "    Validation Loss: 0.647\n",
            "\n",
            "   Epoch 3 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.600\n",
            "    Validation Loss: 0.618\n",
            "\n",
            "   Epoch 4 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.527\n",
            "    Validation Loss: 0.589\n",
            "\n",
            " New Dataframe\n",
            "\n",
            " Fold 1 / 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "   Epoch 1 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.683\n",
            "    Validation Loss: 0.667\n",
            "\n",
            "   Epoch 2 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.631\n",
            "    Validation Loss: 0.627\n",
            "\n",
            "   Epoch 3 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.567\n",
            "    Validation Loss: 0.587\n",
            "\n",
            "   Epoch 4 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.493\n",
            "    Validation Loss: 0.573\n",
            "\n",
            " Fold 2 / 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "   Epoch 1 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.689\n",
            "    Validation Loss: 0.669\n",
            "\n",
            "   Epoch 2 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.635\n",
            "    Validation Loss: 0.632\n",
            "\n",
            "   Epoch 3 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.567\n",
            "    Validation Loss: 0.592\n",
            "\n",
            "   Epoch 4 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.486\n",
            "    Validation Loss: 0.577\n",
            "\n",
            " Fold 3 / 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "   Epoch 1 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.681\n",
            "    Validation Loss: 0.666\n",
            "\n",
            "   Epoch 2 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.613\n",
            "    Validation Loss: 0.624\n",
            "\n",
            "   Epoch 3 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.533\n",
            "    Validation Loss: 0.586\n",
            "\n",
            "   Epoch 4 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.458\n",
            "    Validation Loss: 0.579\n",
            "\n",
            " Fold 4 / 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "   Epoch 1 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.694\n",
            "    Validation Loss: 0.669\n",
            "\n",
            "   Epoch 2 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.629\n",
            "    Validation Loss: 0.629\n",
            "\n",
            "   Epoch 3 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.560\n",
            "    Validation Loss: 0.591\n",
            "\n",
            "   Epoch 4 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.472\n",
            "    Validation Loss: 0.581\n",
            "\n",
            " Fold 5 / 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "   Epoch 1 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.690\n",
            "    Validation Loss: 0.666\n",
            "\n",
            "   Epoch 2 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.637\n",
            "    Validation Loss: 0.630\n",
            "\n",
            "   Epoch 3 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.566\n",
            "    Validation Loss: 0.593\n",
            "\n",
            "   Epoch 4 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.490\n",
            "    Validation Loss: 0.577\n",
            "\n",
            " New Dataframe\n",
            "\n",
            " Fold 1 / 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "   Epoch 1 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.678\n",
            "    Validation Loss: 0.659\n",
            "\n",
            "   Epoch 2 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.620\n",
            "    Validation Loss: 0.610\n",
            "\n",
            "   Epoch 3 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.539\n",
            "    Validation Loss: 0.565\n",
            "\n",
            "   Epoch 4 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.440\n",
            "    Validation Loss: 0.557\n",
            "\n",
            " Fold 2 / 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "   Epoch 1 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.680\n",
            "    Validation Loss: 0.656\n",
            "\n",
            "   Epoch 2 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.607\n",
            "    Validation Loss: 0.611\n",
            "\n",
            "   Epoch 3 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.525\n",
            "    Validation Loss: 0.569\n",
            "\n",
            "   Epoch 4 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.429\n",
            "    Validation Loss: 0.563\n",
            "\n",
            " Fold 3 / 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "   Epoch 1 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.684\n",
            "    Validation Loss: 0.661\n",
            "\n",
            "   Epoch 2 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.630\n",
            "    Validation Loss: 0.614\n",
            "\n",
            "   Epoch 3 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.556\n",
            "    Validation Loss: 0.566\n",
            "\n",
            "   Epoch 4 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.483\n",
            "    Validation Loss: 0.544\n",
            "\n",
            " Fold 4 / 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "   Epoch 1 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.687\n",
            "    Validation Loss: 0.659\n",
            "\n",
            "   Epoch 2 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.623\n",
            "    Validation Loss: 0.610\n",
            "\n",
            "   Epoch 3 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.537\n",
            "    Validation Loss: 0.558\n",
            "\n",
            "   Epoch 4 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.441\n",
            "    Validation Loss: 0.530\n",
            "\n",
            " Fold 5 / 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "   Epoch 1 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.681\n",
            "    Validation Loss: 0.655\n",
            "\n",
            "   Epoch 2 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.616\n",
            "    Validation Loss: 0.605\n",
            "\n",
            "   Epoch 3 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.534\n",
            "    Validation Loss: 0.558\n",
            "\n",
            "   Epoch 4 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.445\n",
            "    Validation Loss: 0.541\n",
            "\n",
            " New Dataframe\n",
            "\n",
            " Fold 1 / 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "   Epoch 1 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.680\n",
            "    Validation Loss: 0.658\n",
            "\n",
            "   Epoch 2 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.612\n",
            "    Validation Loss: 0.604\n",
            "\n",
            "   Epoch 3 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.533\n",
            "    Validation Loss: 0.587\n",
            "\n",
            "   Epoch 4 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.451\n",
            "    Validation Loss: 0.587\n",
            "\n",
            " Fold 2 / 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "   Epoch 1 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.689\n",
            "    Validation Loss: 0.661\n",
            "\n",
            "   Epoch 2 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.609\n",
            "    Validation Loss: 0.600\n",
            "\n",
            "   Epoch 3 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.520\n",
            "    Validation Loss: 0.567\n",
            "\n",
            "   Epoch 4 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.427\n",
            "    Validation Loss: 0.558\n",
            "\n",
            " Fold 3 / 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "   Epoch 1 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.681\n",
            "    Validation Loss: 0.656\n",
            "\n",
            "   Epoch 2 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.604\n",
            "    Validation Loss: 0.598\n",
            "\n",
            "   Epoch 3 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.513\n",
            "    Validation Loss: 0.575\n",
            "\n",
            "   Epoch 4 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            " Validation loss not decreased, Model of previous epoch saved\n",
            "\n",
            " Fold 4 / 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "   Epoch 1 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.676\n",
            "    Validation Loss: 0.656\n",
            "\n",
            "   Epoch 2 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.608\n",
            "    Validation Loss: 0.595\n",
            "\n",
            "   Epoch 3 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            " Validation loss not decreased, Model of previous epoch saved\n",
            "\n",
            " Fold 5 / 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "   Epoch 1 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.683\n",
            "    Validation Loss: 0.656\n",
            "\n",
            "   Epoch 2 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.617\n",
            "    Validation Loss: 0.599\n",
            "\n",
            "   Epoch 3 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.530\n",
            "    Validation Loss: 0.556\n",
            "\n",
            "   Epoch 4 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.442\n",
            "    Validation Loss: 0.554\n",
            "\n",
            " New Dataframe\n",
            "\n",
            " Fold 1 / 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "   Epoch 1 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.668\n",
            "    Validation Loss: 0.645\n",
            "\n",
            "   Epoch 2 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.589\n",
            "    Validation Loss: 0.604\n",
            "\n",
            "   Epoch 3 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.498\n",
            "    Validation Loss: 0.580\n",
            "\n",
            "   Epoch 4 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.387\n",
            "    Validation Loss: 0.557\n",
            "\n",
            " Fold 2 / 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "   Epoch 1 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.670\n",
            "    Validation Loss: 0.644\n",
            "\n",
            "   Epoch 2 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.574\n",
            "    Validation Loss: 0.569\n",
            "\n",
            "   Epoch 3 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.471\n",
            "    Validation Loss: 0.547\n",
            "\n",
            "   Epoch 4 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            " Validation loss not decreased, Model of previous epoch saved\n",
            "\n",
            " Fold 3 / 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "   Epoch 1 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.668\n",
            "    Validation Loss: 0.642\n",
            "\n",
            "   Epoch 2 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.588\n",
            "    Validation Loss: 0.578\n",
            "\n",
            "   Epoch 3 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.480\n",
            "    Validation Loss: 0.543\n",
            "\n",
            "   Epoch 4 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.368\n",
            "    Validation Loss: 0.535\n",
            "\n",
            " Fold 4 / 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "   Epoch 1 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.667\n",
            "    Validation Loss: 0.642\n",
            "\n",
            "   Epoch 2 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.581\n",
            "    Validation Loss: 0.591\n",
            "\n",
            "   Epoch 3 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.489\n",
            "    Validation Loss: 0.560\n",
            "\n",
            "   Epoch 4 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.389\n",
            "    Validation Loss: 0.560\n",
            "\n",
            " Fold 5 / 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "   Epoch 1 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.673\n",
            "    Validation Loss: 0.644\n",
            "\n",
            "   Epoch 2 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.586\n",
            "    Validation Loss: 0.571\n",
            "\n",
            "   Epoch 3 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.476\n",
            "    Validation Loss: 0.543\n",
            "\n",
            "   Epoch 4 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            " Validation loss not decreased, Model of previous epoch saved\n",
            "\n",
            " New Dataframe\n",
            "\n",
            " Fold 1 / 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "   Epoch 1 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.674\n",
            "    Validation Loss: 0.646\n",
            "\n",
            "   Epoch 2 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.594\n",
            "    Validation Loss: 0.589\n",
            "\n",
            "   Epoch 3 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.493\n",
            "    Validation Loss: 0.554\n",
            "\n",
            "   Epoch 4 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            " Validation loss not decreased, Model of previous epoch saved\n",
            "\n",
            " Fold 2 / 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "   Epoch 1 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.673\n",
            "    Validation Loss: 0.644\n",
            "\n",
            "   Epoch 2 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.585\n",
            "    Validation Loss: 0.575\n",
            "\n",
            "   Epoch 3 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.499\n",
            "    Validation Loss: 0.554\n",
            "\n",
            "   Epoch 4 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.401\n",
            "    Validation Loss: 0.548\n",
            "\n",
            " Fold 3 / 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "   Epoch 1 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.672\n",
            "    Validation Loss: 0.645\n",
            "\n",
            "   Epoch 2 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.588\n",
            "    Validation Loss: 0.577\n",
            "\n",
            "   Epoch 3 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.492\n",
            "    Validation Loss: 0.544\n",
            "\n",
            "   Epoch 4 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            " Validation loss not decreased, Model of previous epoch saved\n",
            "\n",
            " Fold 4 / 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "   Epoch 1 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.667\n",
            "    Validation Loss: 0.643\n",
            "\n",
            "   Epoch 2 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.578\n",
            "    Validation Loss: 0.584\n",
            "\n",
            "   Epoch 3 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.477\n",
            "    Validation Loss: 0.546\n",
            "\n",
            "   Epoch 4 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.366\n",
            "    Validation Loss: 0.537\n",
            "\n",
            " Fold 5 / 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "   Epoch 1 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.669\n",
            "    Validation Loss: 0.643\n",
            "\n",
            "   Epoch 2 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.591\n",
            "    Validation Loss: 0.572\n",
            "\n",
            "   Epoch 3 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.478\n",
            "    Validation Loss: 0.537\n",
            "\n",
            "   Epoch 4 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.383\n",
            "    Validation Loss: 0.532\n",
            "\n",
            " New Dataframe\n",
            "\n",
            " Fold 1 / 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "   Epoch 1 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.667\n",
            "    Validation Loss: 0.630\n",
            "\n",
            "   Epoch 2 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.551\n",
            "    Validation Loss: 0.555\n",
            "\n",
            "   Epoch 3 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.438\n",
            "    Validation Loss: 0.532\n",
            "\n",
            "   Epoch 4 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            " Validation loss not decreased, Model of previous epoch saved\n",
            "\n",
            " Fold 2 / 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "   Epoch 1 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.670\n",
            "    Validation Loss: 0.633\n",
            "\n",
            "   Epoch 2 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.569\n",
            "    Validation Loss: 0.567\n",
            "\n",
            "   Epoch 3 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.463\n",
            "    Validation Loss: 0.539\n",
            "\n",
            "   Epoch 4 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.360\n",
            "    Validation Loss: 0.537\n",
            "\n",
            " Fold 3 / 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "   Epoch 1 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.674\n",
            "    Validation Loss: 0.636\n",
            "\n",
            "   Epoch 2 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.577\n",
            "    Validation Loss: 0.562\n",
            "\n",
            "   Epoch 3 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.475\n",
            "    Validation Loss: 0.525\n",
            "\n",
            "   Epoch 4 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.366\n",
            "    Validation Loss: 0.506\n",
            "\n",
            " Fold 4 / 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "   Epoch 1 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.668\n",
            "    Validation Loss: 0.637\n",
            "\n",
            "   Epoch 2 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.578\n",
            "    Validation Loss: 0.568\n",
            "\n",
            "   Epoch 3 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.484\n",
            "    Validation Loss: 0.535\n",
            "\n",
            "   Epoch 4 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            " Validation loss not decreased, Model of previous epoch saved\n",
            "\n",
            " Fold 5 / 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "   Epoch 1 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.670\n",
            "    Validation Loss: 0.633\n",
            "\n",
            "   Epoch 2 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.566\n",
            "    Validation Loss: 0.562\n",
            "\n",
            "   Epoch 3 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            "    Training Loss: 0.464\n",
            "    Validation Loss: 0.531\n",
            "\n",
            "   Epoch 4 / 4\n",
            "\n",
            "   Validating...\n",
            "\n",
            " Validation loss not decreased, Model of previous epoch saved\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAbAsXuJyqzu"
      },
      "source": [
        "Save metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lT5pFIJLypXJ"
      },
      "source": [
        "# quanity_analysis_experts= {\"loss\":loss_lst,\"micro_f1\":micro_f1_lst,\"binary_f1\":binary_f1_lst,\"macro_f1\":macro_f1_lst,\"prec\":prec_lst,\"recall\":recall_lst}\n",
        "\n",
        "# #write\n",
        "# with open('/content/drive/MyDrive/Masterthesis/Results/quanity_analysis_experts.json', 'w') as f:\n",
        "#   json.dump(quanity_analysis_experts, f)\n",
        "\n",
        "#read\n",
        "with open('/content/drive/MyDrive/Masterthesis/Results/quanity_analysis_experts.json') as f:\n",
        "  metrics= json.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtFqnQvqy1Yp"
      },
      "source": [
        "Plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "5WQWB3-Vy1_9",
        "outputId": "18490dbd-38c0-400a-9025-9334a5b4807a"
      },
      "source": [
        "ind = [247,371,494,618,742,865,989,1112,1236]\n",
        "plt.figure(figsize=(7,5))\n",
        "plt.plot(ind,metrics['micro_f1'],label = 'Micro F1')\n",
        "plt.plot(ind,metrics['macro_f1'],label = 'Macro F1')\n",
        "plt.plot(ind,metrics['binary_f1'],label = 'Binary F1')\n",
        "plt.plot(ind,metrics['loss'],label = 'Loss')\n",
        "plt.ylim(0.35,0.9)\n",
        "plt.xlabel('Subsample Size')\n",
        "plt.ylabel('Performance')\n",
        "plt.legend()\n",
        "plt.xticks([247,371,494,618,742,865,989,1112,1236])\n",
        "plt.yticks(np.arange(0.35,0.9,0.05))\n",
        "axes = plt.gca()\n",
        "axes.yaxis.grid()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 504x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}